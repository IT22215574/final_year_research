import requests
from bs4 import BeautifulSoup
import pandas as pd
import os
from datetime import datetime

URL = "https://www.fisheries.gov.lk/web/index.php/en/statistics/weekly-fish-prices"
DATASET_PATH = os.path.join("dataset", "fish_prices.csv")

def fetch_latest_prices():
    print("Fetching latest fish prices from:", URL)
    response = requests.get(URL)
    response.raise_for_status()
    soup = BeautifulSoup(response.text, "html.parser")

    # --- Find the latest table ---
    table = soup.find("table")
    if not table:
        raise ValueError("No data table found on the page.")

    # --- Extract headers and rows ---
    headers = [th.text.strip() for th in table.find_all("th")]
    rows = []
    for tr in table.find_all("tr")[1:]:
        cols = [td.text.strip() for td in tr.find_all("td")]
        if cols:
            rows.append(cols)

    df_new = pd.DataFrame(rows, columns=headers)

    # Basic cleanup
    df_new = df_new.rename(columns={
        "Date": "Date",
        "Fish Type": "FishType",
        "Market": "Market",
        "Price (LKR/kg)": "Price_LKR_per_kg"
    })

    df_new["Date"] = pd.to_datetime(df_new["Date"], errors="coerce")
    df_new = df_new.dropna(subset=["Date", "FishType", "Price_LKR_per_kg"])
    df_new["Price_LKR_per_kg"] = pd.to_numeric(df_new["Price_LKR_per_kg"], errors="coerce")

    os.makedirs("dataset", exist_ok=True)

    if os.path.exists(DATASET_PATH):
        df_old = pd.read_csv(DATASET_PATH)
        df_combined = pd.concat([df_old, df_new]).drop_duplicates(subset=["Date", "FishType", "Market"], keep="last")
    else:
        df_combined = df_new

    df_combined.to_csv(DATASET_PATH, index=False)
    print(f"✅ Dataset updated successfully at {DATASET_PATH} with {len(df_combined)} rows.")

if __name__ == "__main__":
    try:
        fetch_latest_prices()
        print("Scraping complete!")
    except Exception as e:
        print("❌ Error fetching data:", e)
